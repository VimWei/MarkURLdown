from __future__ import annotations

from dataclasses import dataclass
import time
import random
from typing import Optional, Callable, Any

from bs4 import BeautifulSoup

from markitdown_app.core.html_to_md import html_fragment_to_markdown

@dataclass
class CrawlerResult:
    """çˆ¬è™«ç»“æœ"""
    success: bool
    title: str | None
    text_content: str
    error: str | None = None

@dataclass
class FetchResult:
    title: str | None
    html_markdown: str

def fetch_zhihu_article(session, url: str, on_detail: Optional[Callable[[str], None]] = None, shared_browser: Any | None = None) -> FetchResult:
    """
    è·å–çŸ¥ä¹ä¸“æ æ–‡ç« å†…å®¹
    ä½¿ç”¨ Playwright - ç°ä»£åŒ–æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆæœ€å¯é ï¼Œèƒ½å¤„ç†çŸ¥ä¹éªŒè¯ï¼‰
    """

    # ä½¿ç”¨Playwrightçˆ¬è™«å¤„ç†çŸ¥ä¹æ–‡ç« 
    max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡

    for retry in range(max_retries):
        try:
            if retry > 0:
                print(f"å°è¯•çŸ¥ä¹è·å– (é‡è¯• {retry}/{max_retries-1})...")
                time.sleep(random.uniform(3, 6))  # é‡è¯•æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
            else:
                print("å°è¯•çŸ¥ä¹è·å–...")

            result = _try_playwright_crawler(url, on_detail, shared_browser)
            if result.success:
                # æ˜¾ç¤ºå†…å®¹è·å–æˆåŠŸçŠ¶æ€
                if on_detail:
                    on_detail("çŸ¥ä¹å†…å®¹è·å–æˆåŠŸï¼Œæ­£åœ¨å¤„ç†...")

                # å¤„ç†å†…å®¹å¹¶æ£€æŸ¥è´¨é‡
                processed_result = _process_zhihu_content(result.text_content, result.title, url)

                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°éªŒè¯é¡µé¢ - æ›´ç²¾ç¡®çš„æ£€æµ‹
                content = processed_result.html_markdown or ""
                if content and len(content) > 1000:  # å¦‚æœå†…å®¹è¶³å¤Ÿé•¿ï¼Œè¯´æ˜ä¸æ˜¯éªŒè¯é¡µé¢
                    print("æˆåŠŸè·å–åˆ°å†…å®¹!")
                    return processed_result
                elif content and ("éªŒè¯" in content or "ç™»å½•" in content or "è®¿é—®è¢«æ‹’ç»" in content or "403" in content or "404" in content):
                    print("è·å–åˆ°éªŒè¯é¡µé¢ï¼Œé‡è¯•...")
                    if retry < max_retries - 1:
                        continue
                    else:
                        print("é‡è¯•æ¬¡æ•°ç”¨å°½")
                        break

                # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«éªŒè¯ä¿¡æ¯
                if processed_result.title and ("éªŒè¯" in processed_result.title or "ç™»å½•" in processed_result.title or "è®¿é—®è¢«æ‹’ç»" in processed_result.title):
                    print("æ ‡é¢˜åŒ…å«éªŒè¯ä¿¡æ¯ï¼Œé‡è¯•...")
                    if retry < max_retries - 1:
                        continue
                    else:
                        print("é‡è¯•æ¬¡æ•°ç”¨å°½")
                        break

                print("æˆåŠŸ!")
                return processed_result
            else:
                print(f"è·å–å¤±è´¥: {result.error}")
                if retry < max_retries - 1:
                    continue
                else:
                    break
        except Exception as e:
            print(f"è·å–å¼‚å¸¸: {e}")
            if retry < max_retries - 1:
                continue
            else:
                break

    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œç”¨æˆ·æŒ‡å¯¼
    print("âš ï¸  çŸ¥ä¹æ–‡ç« çˆ¬å–é‡åˆ°é™åˆ¶")
    print("ğŸ’¡ å»ºè®®:")
    print("   1. å°è¯•ä½¿ç”¨VPNæˆ–ä»£ç†")
    print("   2. è”ç³»æ–‡ç« ä½œè€…è·å–æˆæƒ")
    print("   3. ä½¿ç”¨å…¶ä»–å·¥å…·æ‰‹åŠ¨å¤åˆ¶å†…å®¹")
    print("   4. å°è¯•åœ¨æµè§ˆå™¨ä¸­ç›´æ¥è®¿é—®æ–‡ç« ")
    raise Exception("çŸ¥ä¹æ–‡ç« çˆ¬å–å¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–æ–¹æ³•")

def _try_playwright_crawler(url: str, on_detail: Optional[Callable[[str], None]] = None, shared_browser: Any | None = None) -> CrawlerResult:
    """å°è¯•ä½¿ç”¨ Playwright çˆ¬è™« - èƒ½å¤„ç†çŸ¥ä¹çš„éªŒè¯æœºåˆ¶"""
    try:
        # åˆ†æ”¯1ï¼šå…±äº« Browserï¼ˆä¸ºæ¯ä¸ª URL æ–°å»º Contextï¼‰
        if shared_browser is not None:
            context = shared_browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='zh-CN',
                timezone_id='Asia/Shanghai',
                geolocation={'latitude': 39.9042, 'longitude': 116.4074},  # åŒ—äº¬åæ ‡
                permissions=['geolocation'],
                extra_http_headers={
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Sec-Fetch-User': '?1',
                    'Cache-Control': 'max-age=0',
                }
            )
            page = context.new_page()
            # æ³¨å…¥åæ£€æµ‹è„šæœ¬
            page.add_init_script("""
                // éšè—webdriverå±æ€§
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined,
                });

                // æ¨¡æ‹ŸçœŸå®çš„navigatorå±æ€§
                Object.defineProperty(navigator, 'plugins', {
                    get: () => [1, 2, 3, 4, 5],
                });

                Object.defineProperty(navigator, 'languages', {
                    get: () => ['zh-CN', 'zh', 'en'],
                });

                // æ¨¡æ‹ŸçœŸå®çš„å±å¹•å±æ€§
                Object.defineProperty(screen, 'width', {
                    get: () => 1920,
                });

                Object.defineProperty(screen, 'height', {
                    get: () => 1080,
                });

                // æ¨¡æ‹ŸçœŸå®çš„æ—¶åŒº
                Object.defineProperty(Intl.DateTimeFormat.prototype, 'resolvedOptions', {
                    value: function() {
                        return { timeZone: 'Asia/Shanghai' };
                    }
                });
            """)
            page.set_default_timeout(30000)

            # é¦–é¡µ â†’ ç›®æ ‡æ–‡ç« æµç¨‹
            try:
                print("Playwright: æ­£åœ¨è®¿é—®çŸ¥ä¹é¦–é¡µå»ºç«‹ä¼šè¯...")
                if on_detail:
                    on_detail("æ­£åœ¨è®¿é—®çŸ¥ä¹é¦–é¡µå»ºç«‹ä¼šè¯...")
                home_response = page.goto("https://www.zhihu.com/", wait_until='domcontentloaded', timeout=15000)
                if home_response and home_response.status == 200:
                    page.wait_for_timeout(random.uniform(2000, 4000))
                    try:
                        page.wait_for_timeout(random.uniform(500, 1500))
                        login_selectors = [
                            '.Modal-closeButton', '.SignFlow-close', '[aria-label="å…³é—­"]',
                            '.Modal-close', '.close-button', 'button[aria-label="å…³é—­"]'
                        ]
                        login_close = None
                        for selector in login_selectors:
                            login_close = page.query_selector(selector)
                            if login_close:
                                break
                        if login_close:
                            try:
                                login_close.click(timeout=3000)
                            except:
                                try:
                                    login_close.click(force=True, timeout=2000)
                                except:
                                    try:
                                        page.evaluate("arguments[0].click()", login_close)
                                    except:
                                        page.keyboard.press('Escape')
                            page.wait_for_timeout(500)
                    except Exception:
                        pass
            except Exception as e:
                print(f"Playwright: è®¿é—®çŸ¥ä¹é¦–é¡µå¤±è´¥: {e}")

            # è®¿é—®ç›®æ ‡æ–‡ç« 
            print("Playwright: ç›´æ¥è®¿é—®ç›®æ ‡æ–‡ç« ...")
            if on_detail:
                on_detail("æ­£åœ¨è®¿é—®ç›®æ ‡æ–‡ç« ...")
            response = page.goto(url, wait_until='domcontentloaded', timeout=30000)

            # ç­‰å¾…ç¨³å®šä¸å¤„ç†å¼¹çª—
            page.wait_for_timeout(random.uniform(1000, 2000))
            try:
                login_selectors = [
                    '.Modal-closeButton', '.SignFlow-close', '[aria-label="å…³é—­"]', '.Modal-close',
                    '.close-button', 'button[aria-label="å…³é—­"]', '.ant-modal-close', '.el-dialog__close'
                ]
                login_close = None
                for selector in login_selectors:
                    login_close = page.query_selector(selector)
                    if login_close:
                        break
                if login_close:
                    try:
                        login_close.click(timeout=5000)
                    except:
                        try:
                            login_close.click(force=True, timeout=3000)
                        except:
                            try:
                                page.evaluate("arguments[0].click()", login_close)
                            except:
                                try:
                                    page.keyboard.press('Escape')
                                except:
                                    pass
                    page.wait_for_timeout(1000)
            except Exception as e:
                try:
                    page.keyboard.press('Escape')
                except:
                    pass

            page.wait_for_timeout(random.uniform(1000, 2000))
            try:
                page.wait_for_selector('div.Post-RichTextContainer, div.Post-RichText, article, div.content', timeout=10000)
            except:
                pass

            if on_detail:
                on_detail("æ­£åœ¨è·å–é¡µé¢å†…å®¹...")
            html = page.content()
            title = None
            try:
                title = page.title()
            except:
                pass

            try:
                page.close()
            except Exception:
                pass
            try:
                context.close()
            except Exception:
                pass

            return CrawlerResult(success=True, title=title, text_content=html)

        # åˆ†æ”¯2ï¼šæ¯ URL ç‹¬ç«‹ Browserï¼ˆåŸè·¯å¾„ï¼‰
        from playwright.sync_api import sync_playwright
        with sync_playwright() as p:
            # å¯åŠ¨çœŸå®çš„Chromeæµè§ˆå™¨ï¼Œä½¿ç”¨æˆåŠŸçš„åæ£€æµ‹é…ç½®
            browser = p.chromium.launch(
                headless=False,  # ä½¿ç”¨éheadlessæ¨¡å¼ä»¥ç»•è¿‡æ£€æµ‹
                channel="chrome",  # ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„Chrome
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor',
                    '--disable-gpu',
                    '--no-first-run',
                    '--no-default-browser-check',
                    '--disable-extensions',
                    '--disable-plugins',
                    '--disable-background-timer-throttling',
                    '--disable-backgrounding-occluded-windows',
                    '--disable-renderer-backgrounding',
                ]
            )

            # åˆ›å»ºä¸Šä¸‹æ–‡ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·ç¯å¢ƒ
            context = browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='zh-CN',
                timezone_id='Asia/Shanghai',
                geolocation={'latitude': 39.9042, 'longitude': 116.4074},  # åŒ—äº¬åæ ‡
                permissions=['geolocation'],
                extra_http_headers={
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Sec-Fetch-User': '?1',
                    'Cache-Control': 'max-age=0',
                }
            )

            # åˆ›å»ºé¡µé¢
            page = context.new_page()

            # æ³¨å…¥åæ£€æµ‹è„šæœ¬
            page.add_init_script("""
                // éšè—webdriverå±æ€§
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined,
                });

                // æ¨¡æ‹ŸçœŸå®çš„navigatorå±æ€§
                Object.defineProperty(navigator, 'plugins', {
                    get: () => [1, 2, 3, 4, 5],
                });

                Object.defineProperty(navigator, 'languages', {
                    get: () => ['zh-CN', 'zh', 'en'],
                });

                // æ¨¡æ‹ŸçœŸå®çš„å±å¹•å±æ€§
                Object.defineProperty(screen, 'width', {
                    get: () => 1920,
                });

                Object.defineProperty(screen, 'height', {
                    get: () => 1080,
                });

                // æ¨¡æ‹ŸçœŸå®çš„æ—¶åŒº
                Object.defineProperty(Intl.DateTimeFormat.prototype, 'resolvedOptions', {
                    value: function() {
                        return { timeZone: 'Asia/Shanghai' };
                    }
                });
            """)

            # è®¾ç½®è¶…æ—¶
            page.set_default_timeout(30000)

            # è®¿é—®é¡µé¢
            print(f"Playwright: æ­£åœ¨è®¿é—® {url}")
            if on_detail:
                on_detail("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨è®¿é—®çŸ¥ä¹...")

            # ä¼˜åŒ–çš„è®¿é—®æµç¨‹ï¼šé¦–é¡µ â†’ ç›®æ ‡æ–‡ç« 
            try:
                # 1. å…ˆè®¿é—®çŸ¥ä¹é¦–é¡µå»ºç«‹ä¼šè¯
                print("Playwright: æ­£åœ¨è®¿é—®çŸ¥ä¹é¦–é¡µå»ºç«‹ä¼šè¯...")
                if on_detail:
                    on_detail("æ­£åœ¨è®¿é—®çŸ¥ä¹é¦–é¡µå»ºç«‹ä¼šè¯...")
                home_response = page.goto("https://www.zhihu.com/", wait_until='domcontentloaded', timeout=15000)
                if home_response and home_response.status == 200:
                    print("Playwright: çŸ¥ä¹é¦–é¡µè®¿é—®æˆåŠŸï¼Œè·å–cookies...")
                    # æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸ºï¼šç­‰å¾…é¡µé¢åŠ è½½
                    page.wait_for_timeout(random.uniform(2000, 4000))

                    # æ¨¡æ‹Ÿé¼ æ ‡ç§»åŠ¨
                    page.mouse.move(random.randint(100, 800), random.randint(100, 400))
                    page.wait_for_timeout(random.uniform(500, 1500))

                    # æ™ºèƒ½å¤„ç†é¦–é¡µç™»å½•å¼¹çª—
                    try:
                        # ç­‰å¾…å¼¹çª—å¯èƒ½å‡ºç°çš„æ—¶æœº
                        page.wait_for_timeout(random.uniform(500, 1500))

                        login_selectors = [
                            '.Modal-closeButton',
                            '.SignFlow-close',
                            '[aria-label="å…³é—­"]',
                            '.Modal-close',
                            '.close-button',
                            'button[aria-label="å…³é—­"]'
                        ]

                        login_close = None
                        for selector in login_selectors:
                            login_close = page.query_selector(selector)
                            if login_close:
                                break

                        if login_close:
                            print("Playwright: å‘ç°é¦–é¡µç™»å½•å¼¹çª—ï¼Œå°è¯•å…³é—­...")

                            # å¤šç§å…³é—­ç­–ç•¥
                            try:
                                login_close.click(timeout=3000)
                                print("Playwright: é¦–é¡µå¼¹çª—ç›´æ¥ç‚¹å‡»æˆåŠŸ")
                            except:
                                try:
                                    login_close.click(force=True, timeout=2000)
                                    print("Playwright: é¦–é¡µå¼¹çª—å¼ºåˆ¶ç‚¹å‡»æˆåŠŸ")
                                except:
                                    try:
                                        page.evaluate("arguments[0].click()", login_close)
                                        print("Playwright: é¦–é¡µå¼¹çª—JavaScriptç‚¹å‡»æˆåŠŸ")
                                    except:
                                        page.keyboard.press('Escape')
                                        print("Playwright: é¦–é¡µå¼¹çª—ä½¿ç”¨ESCé”®å…³é—­")

                            page.wait_for_timeout(500)
                        else:
                            print("Playwright: é¦–é¡µæœªå‘ç°ç™»å½•å¼¹çª—")
                    except Exception as e:
                        print(f"Playwright: å¤„ç†é¦–é¡µç™»å½•å¼¹çª—å¼‚å¸¸: {e}")
                else:
                    print("Playwright: çŸ¥ä¹é¦–é¡µè®¿é—®å¤±è´¥")
            except Exception as e:
                print(f"Playwright: è®¿é—®çŸ¥ä¹é¦–é¡µå¤±è´¥: {e}")

            # 2. ç›´æ¥è®¿é—®ç›®æ ‡æ–‡ç« 
            print("Playwright: ç›´æ¥è®¿é—®ç›®æ ‡æ–‡ç« ...")
            if on_detail:
                on_detail("æ­£åœ¨è®¿é—®ç›®æ ‡æ–‡ç« ...")
            response = page.goto(url, wait_until='domcontentloaded', timeout=30000)

            # æ™ºèƒ½ç­‰å¾…é¡µé¢ç¨³å®šå¹¶å¤„ç†ç™»å½•å¼¹çª—
            print("Playwright: ç­‰å¾…é¡µé¢ç¨³å®šå¹¶å¤„ç†ç™»å½•å¼¹çª—...")

            # ç­‰å¾…é¡µé¢åŸºæœ¬åŠ è½½å®Œæˆ
            page.wait_for_timeout(random.uniform(1000, 2000))

            # æ™ºèƒ½å¤„ç†ç™»å½•å¼¹çª— - å¤šç§ç­–ç•¥
            try:
                # æŸ¥æ‰¾å„ç§å¯èƒ½çš„ç™»å½•å¼¹çª—å…³é—­æŒ‰é’®
                login_selectors = [
                    '.Modal-closeButton',
                    '.SignFlow-close',
                    '[aria-label="å…³é—­"]',
                    '.Modal-close',
                    '.close-button',
                    'button[aria-label="å…³é—­"]',
                    '.ant-modal-close',
                    '.el-dialog__close'
                ]

                login_close = None
                for selector in login_selectors:
                    login_close = page.query_selector(selector)
                    if login_close:
                        break

                if login_close:
                    print("Playwright: å‘ç°ç™»å½•å¼¹çª—ï¼Œå°è¯•å…³é—­...")

                    # ç­–ç•¥1: ç›´æ¥ç‚¹å‡»
                    try:
                        login_close.click(timeout=5000)
                        print("Playwright: ç›´æ¥ç‚¹å‡»æˆåŠŸ")
                    except:
                        # ç­–ç•¥2: å¼ºåˆ¶ç‚¹å‡»
                        try:
                            login_close.click(force=True, timeout=3000)
                            print("Playwright: å¼ºåˆ¶ç‚¹å‡»æˆåŠŸ")
                        except:
                            # ç­–ç•¥3: ä½¿ç”¨JavaScriptç‚¹å‡»
                            try:
                                page.evaluate("arguments[0].click()", login_close)
                                print("Playwright: JavaScriptç‚¹å‡»æˆåŠŸ")
                            except:
                                # ç­–ç•¥4: æŒ‰ESCé”®å…³é—­å¼¹çª—
                                try:
                                    page.keyboard.press('Escape')
                                    print("Playwright: ä½¿ç”¨ESCé”®å…³é—­å¼¹çª—")
                                except:
                                    print("Playwright: æ‰€æœ‰å…³é—­ç­–ç•¥éƒ½å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ...")

                    # çŸ­æš‚ç­‰å¾…ç¡®è®¤å¼¹çª—å…³é—­
                    page.wait_for_timeout(1000)
                else:
                    print("Playwright: æœªå‘ç°ç™»å½•å¼¹çª—")

            except Exception as e:
                print(f"Playwright: å¤„ç†ç™»å½•å¼¹çª—å¼‚å¸¸: {e}")
                # å°è¯•æŒ‰ESCé”®ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                try:
                    page.keyboard.press('Escape')
                    print("Playwright: ä½¿ç”¨ESCé”®ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                except:
                    pass

            # æœ€ç»ˆç­‰å¾…é¡µé¢å®Œå…¨ç¨³å®š
            page.wait_for_timeout(random.uniform(1000, 2000))

            # æ£€æŸ¥é¡µé¢æ ‡é¢˜è€Œä¸æ˜¯å“åº”çŠ¶æ€ï¼Œå› ä¸ºçŸ¥ä¹å¯èƒ½è¿”å›200ä½†å†…å®¹æ˜¯403é¡µé¢
            try:
                page_title = page.title()
                print(f"Playwright: è·å–åˆ°æ ‡é¢˜: {page_title}")
                if "403" in page_title or "Forbidden" in page_title:
                    browser.close()
                    return CrawlerResult(
                        success=False,
                        title=None,
                        text_content="",
                        error=f"Page title indicates 403: {page_title}"
                    )
            except Exception as e:
                print(f"Playwright: è·å–æ ‡é¢˜å¤±è´¥: {e}")
                # ç»§ç»­æ‰§è¡Œï¼Œå¯èƒ½é¡µé¢æ­£åœ¨åŠ è½½

            # æ¨¡æ‹ŸçœŸå®ç”¨æˆ·é˜…è¯»è¡Œä¸º
            page.wait_for_timeout(random.uniform(3000, 6000))

            # æ¨¡æ‹Ÿé¼ æ ‡ç§»åŠ¨å’Œæ»šåŠ¨
            page.mouse.move(random.randint(300, 700), random.randint(300, 600))
            page.wait_for_timeout(random.uniform(500, 1500))
            page.mouse.wheel(0, random.randint(100, 400))
            page.wait_for_timeout(random.uniform(1000, 2000))

            # å°è¯•ç­‰å¾…ç‰¹å®šå…ƒç´ åŠ è½½
            try:
                # ç­‰å¾…å†…å®¹åŒºåŸŸåŠ è½½
                page.wait_for_selector('div.Post-RichTextContainer, div.Post-RichText, article, div.content', timeout=10000)
                print("Playwright: æ‰¾åˆ°å†…å®¹åŒºåŸŸ")
            except:
                print("Playwright: æœªæ‰¾åˆ°å†…å®¹åŒºåŸŸï¼Œä½†ç»§ç»­è·å–é¡µé¢å†…å®¹...")

            # è·å–é¡µé¢å†…å®¹
            if on_detail:
                on_detail("æ­£åœ¨è·å–é¡µé¢å†…å®¹...")
            html = page.content()

            # å°è¯•è·å–æ ‡é¢˜
            title = None
            try:
                title = page.title()
                print(f"Playwright: è·å–åˆ°æ ‡é¢˜: {title}")
            except:
                pass

            browser.close()

            return CrawlerResult(
                success=True,
                title=title,
                text_content=html
            )

    except ImportError:
        return CrawlerResult(
            success=False,
            title=None,
            text_content="",
            error="Playwright not installed. Install with: pip install playwright && playwright install"
        )
    except Exception as e:
        return CrawlerResult(
            success=False,
            title=None,
            text_content="",
            error=f"Playwright error: {str(e)}"
        )

def _clean_zhihu_zhida_links(content_elem):
    """æ¸…ç†çŸ¥ä¹ç›´ç­”é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬å†…å®¹ï¼Œç§»é™¤é“¾æ¥"""
    import re
    from bs4 import NavigableString

    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«çŸ¥ä¹ç›´ç­”é“¾æ¥çš„<a>æ ‡ç­¾
    zhida_links = content_elem.find_all('a', href=re.compile(r'https://zhida\.zhihu\.com/search\?'))

    for link in zhida_links:
        # è·å–é“¾æ¥æ–‡æœ¬
        link_text = link.get_text(strip=True)

        # å¦‚æœé“¾æ¥æ–‡æœ¬ä¸ä¸ºç©ºï¼Œç”¨çº¯æ–‡æœ¬æ›¿æ¢é“¾æ¥
        if link_text:
            # åˆ›å»ºçº¯æ–‡æœ¬èŠ‚ç‚¹
            text_node = NavigableString(link_text)
            # ç”¨çº¯æ–‡æœ¬æ›¿æ¢é“¾æ¥
            link.replace_with(text_node)
        else:
            # å¦‚æœé“¾æ¥æ–‡æœ¬ä¸ºç©ºï¼Œç›´æ¥ç§»é™¤
            link.decompose()

    # é¢å¤–å¤„ç†ï¼šæ¸…ç†å¯èƒ½å­˜åœ¨çš„å…¶ä»–çŸ¥ä¹å†…éƒ¨é“¾æ¥
    internal_links = content_elem.find_all('a', href=re.compile(r'https://www\.zhihu\.com/(question|answer|p)/'))

    for link in internal_links:
        link_text = link.get_text(strip=True)
        if link_text:
            text_node = NavigableString(link_text)
            link.replace_with(text_node)
        else:
            link.decompose()

def _clean_zhihu_external_links(content_elem):
    """æ¸…ç†çŸ¥ä¹å¤–éƒ¨é“¾æ¥é‡å®šå‘ï¼Œæ¢å¤åŸå§‹é“¾æ¥"""
    import re
    from urllib.parse import unquote, urlparse, parse_qs
    from bs4 import NavigableString

    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«çŸ¥ä¹é‡å®šå‘é“¾æ¥çš„<a>æ ‡ç­¾
    redirect_links = content_elem.find_all('a', href=re.compile(r'https://link\.zhihu\.com/\?target='))

    for link in redirect_links:
        href = link.get('href', '')

        try:
            # è§£æURLå‚æ•°
            parsed_url = urlparse(href)
            query_params = parse_qs(parsed_url.query)

            # è·å–targetå‚æ•°
            if 'target' in query_params and query_params['target']:
                target_url = query_params['target'][0]
                # URLè§£ç 
                decoded_url = unquote(target_url)

                # æ›´æ–°é“¾æ¥çš„hrefå±æ€§
                link['href'] = decoded_url
                print(f"Playwright: æ¢å¤å¤–éƒ¨é“¾æ¥: {href} -> {decoded_url}")
            else:
                # å¦‚æœtargetå‚æ•°ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œå°†é“¾æ¥è½¬æ¢ä¸ºçº¯æ–‡æœ¬
                link_text = link.get_text(strip=True)
                if link_text:
                    text_node = NavigableString(link_text)
                    link.replace_with(text_node)
                    print(f"Playwright: è½¬æ¢æ— æ•ˆé‡å®šå‘é“¾æ¥ä¸ºçº¯æ–‡æœ¬: {href}")
                else:
                    link.decompose()
                    print(f"Playwright: ç§»é™¤ç©ºçš„é‡å®šå‘é“¾æ¥: {href}")

        except Exception as e:
            print(f"Playwright: å¤„ç†é‡å®šå‘é“¾æ¥å¼‚å¸¸: {e}")
            # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè½¬æ¢ä¸ºçº¯æ–‡æœ¬
            link_text = link.get_text(strip=True)
            if link_text:
                text_node = NavigableString(link_text)
                link.replace_with(text_node)
            else:
                link.decompose()
            continue

def _process_zhihu_content(html: str, title: str | None = None, url: str | None = None) -> FetchResult:
    """å¤„ç†çŸ¥ä¹å†…å®¹ï¼Œæå–æ ‡é¢˜ã€ä½œè€…ã€å‘å¸ƒæ—¥æœŸå’Œæ­£æ–‡"""
    try:
        soup = BeautifulSoup(html, 'lxml')
    except Exception as e:
        print(f"BeautifulSoupè§£æå¤±è´¥: {e}")
        return FetchResult(title=None, html_markdown="")

    # æŸ¥æ‰¾æ ‡é¢˜ - çŸ¥ä¹ä¸“æ çš„æ ‡é¢˜é€‰æ‹©å™¨
    if not title:
        title_elem = (
            soup.find('h1', class_='Post-Title') or
            soup.find('h1', class_='ArticleItem-title') or
            soup.find('h1', class_='Post-Title') or
            soup.find(attrs={'property': 'og:title'}) or
            soup.find(attrs={'property': 'twitter:title'}) or
            soup.find('h1') or
            soup.find('title')
        )
        if title_elem:
            title = getattr(title_elem, 'get', lambda *_: None)('content') or title_elem.get_text(strip=True)

    # æŸ¥æ‰¾ä½œè€…ä¿¡æ¯
    author = None
    # é¦–å…ˆå°è¯•ä»metaæ ‡ç­¾è·å–
    author_meta = soup.find('meta', {'name': 'author'}) or soup.find('meta', {'property': 'article:author'})
    if author_meta:
        author = author_meta.get('content', '').strip()

    # å…¶æ¬¡å°è¯•ä»ä½œè€…ä¿¡æ¯å®¹å™¨ä¸­æå–ï¼ˆçŸ¥ä¹é¡µé¢å¸¸è§ï¼šdiv.AuthorInfo-contentï¼‰
    if not author:
        author_info = soup.select_one('div.AuthorInfo-content')
        if author_info:
            # ä¼˜å…ˆå–å¸¦æœ‰ä½œè€…åå­—çš„å¯è§æ–‡æœ¬
            # å¸¸è§ç»“æ„å« a.AuthorInfo-name æˆ– span ç­‰
            name_elem = author_info.select_one('.AuthorInfo-name, a, span')
            if name_elem:
                candidate = name_elem.get_text(strip=True)
                if candidate:
                    author = candidate
            if not author:
                text = author_info.get_text(" ", strip=True)
                if text:
                    author = text

    # å¦‚æœä¸Šè¿°æ–¹å¼æ²¡æœ‰ä½œè€…ä¿¡æ¯ï¼Œå°è¯•ä»æ–‡ç« å†…å®¹ä¸­æå–
    if not author:
        # æŸ¥æ‰¾åŒ…å«ä½œè€…ä¿¡æ¯çš„æ–‡æœ¬æ¨¡å¼
        content_elem = soup.find('div', class_='Post-RichTextContainer') or soup.find('div', class_='Post-RichText')
        if content_elem:
            # æŸ¥æ‰¾åŒ…å«"ä½œè€…ï¼š"ã€"æ–‡/"ç­‰å…³é”®è¯çš„æ–‡æœ¬
            author_patterns = [
                r'ä½œè€…[ï¼š:]\s*([^**\n]+)',
                r'æ–‡/.*?ï¼š([^**\n]+)',
                r'ç¼–è¾‘[ï¼š:]\s*([^**\n]+)',
                r'æ¥æº[ï¼š:]\s*([^**\n]+)'
            ]

            import re
            content_text = content_elem.get_text()
            for pattern in author_patterns:
                match = re.search(pattern, content_text)
                if match:
                    author = match.group(1).strip()
                    # æ¸…ç†ä½œè€…åç§°ï¼Œç§»é™¤å¤šä½™ä¿¡æ¯
                    author = re.sub(r'ï¼ˆ.*?ï¼‰', '', author)
                    author = re.sub(r'çŸ¥ä¹.*', '', author)
                    author = author.strip()
                    if author:
                        break

    # æŸ¥æ‰¾å‘å¸ƒæ—¥æœŸ
    publish_date = None
    date_selectors = [
        'time[datetime]',
        'div.ContentItem-time',
        'span[data-tooltip]',
        'div.Post-Header .ContentItem-time',
        'meta[property="article:published_time"]',
        'meta[name="publish_time"]'
    ]

    for selector in date_selectors:
        elem = soup.select_one(selector)
        if elem:
            if elem.name == 'meta':
                publish_date = elem.get('content', '').strip()
            elif elem.get('datetime'):
                publish_date = elem.get('datetime', '').strip()
            else:
                # ContentItem-time å¸¸ä½äºåŒ…å«ç›¸å¯¹æ—¶é—´/tooltip çš„å®¹å™¨
                # è·å–å°½é‡å¹²å‡€çš„å¯è§æ–‡æœ¬
                publish_date = elem.get_text(strip=True)
            if publish_date:
                break

    # æŸ¥æ‰¾å†…å®¹åŒºåŸŸ - çŸ¥ä¹ä¸“æ çš„å†…å®¹é€‰æ‹©å™¨
    content_elem = None
    content_selectors = [
        'div.Post-RichTextContainer',
        'div[data-zop-feedtype]',
        'div.Post-RichText',
        'div.ArticleItem-content',
        'div.entry-content',
        'article',
        'div.content'
    ]

    for selector in content_selectors:
        content_elem = soup.select_one(selector)
        if content_elem:
            break

    if content_elem:
        # å¤„ç†çŸ¥ä¹ç‰¹æœ‰çš„å›¾ç‰‡æ‡’åŠ è½½
        for img in content_elem.find_all('img', {'data-src': True}):
            img['src'] = img['data-src']
            del img['data-src']

        # å¤„ç†çŸ¥ä¹çš„å›¾ç‰‡å ä½ç¬¦
        for img in content_elem.find_all('img', {'data-original': True}):
            img['src'] = img['data-original']
            del img['data-original']

        # ç§»é™¤è„šæœ¬å’Œæ ·å¼
        for script in content_elem.find_all(['script', 'style']):
            script.decompose()

        # ç§»é™¤çŸ¥ä¹ç‰¹æœ‰çš„æ— ç”¨å…ƒç´ 
        for elem in content_elem.find_all(['div'], class_=['Post-RichTextContainer']):
            # ä¿ç•™ä¸»è¦å†…å®¹ï¼Œç§»é™¤å¹¿å‘Šç­‰
            pass

        # ç§»é™¤çŸ¥ä¹çš„æ¨èå†…å®¹
        for elem in content_elem.find_all(['div'], class_=['Recommendation-Main', 'Card', 'Card--padding']):
            elem.decompose()

        # æ¸…ç†çŸ¥ä¹ç›´ç­”é“¾æ¥ - ä¿ç•™æ–‡æœ¬ï¼Œç§»é™¤é“¾æ¥
        _clean_zhihu_zhida_links(content_elem)

        # æ¸…ç†çŸ¥ä¹å¤–éƒ¨é“¾æ¥é‡å®šå‘ - æ¢å¤åŸå§‹é“¾æ¥
        _clean_zhihu_external_links(content_elem)

        # æ³¨æ„ï¼šå›¾ç‰‡æ ¼å¼æ£€æµ‹å·²ç§»è‡³å›¾ç‰‡ä¸‹è½½é˜¶æ®µå¤„ç†ï¼Œä»¥æå‡å†…å®¹å¤„ç†é€Ÿåº¦

        md = html_fragment_to_markdown(content_elem)
    else:
        md = ""

    # æ„å»ºå®Œæ•´çš„markdownå†…å®¹ï¼ŒåŒ…å«æ ‡é¢˜ã€URLã€ä½œè€…ã€å‘å¸ƒæ—¥æœŸ
    header_parts = []

    # æ·»åŠ æ ‡é¢˜
    if title:
        header_parts.append(f"# {title}")

    # æ·»åŠ æ–‡ç« é“¾æ¥URL
    if url:
        header_parts.append(f"**æ¥æºï¼š** {url}")

    # æ·»åŠ ä½œè€…å’Œå‘å¸ƒæ—¥æœŸä¿¡æ¯
    if author or publish_date:
        meta_info = []
        if author:
            meta_info.append(f"**ä½œè€…ï¼š** {author}")
        if publish_date:
            meta_info.append(f"**å‘å¸ƒæ—¶é—´ï¼š** {publish_date}")

        if meta_info:
            header_parts.append("\n".join(meta_info))

    # å¦‚æœæœ‰æ ‡é¢˜æˆ–å…ƒä¿¡æ¯ï¼Œæ·»åŠ åˆ°markdownå¼€å¤´
    if header_parts:
        header = "\n\n".join(header_parts) + "\n\n"
        md = header + md if md else header

    # å¦‚æœæ‰¾åˆ°äº†å†…å®¹ä½†æ²¡æœ‰æ ‡é¢˜ï¼Œå°è¯•ä»é¡µé¢å…¶ä»–åœ°æ–¹è·å–
    elif not title and md:
        # å°è¯•ä»metaæ ‡ç­¾è·å–
        meta_title = soup.find('meta', {'property': 'og:title'})
        if meta_title:
            title = meta_title.get('content', '').strip()

        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»é¡µé¢æ ‡é¢˜è·å–
        if not title:
            page_title = soup.find('title')
            if page_title:
                title = page_title.get_text(strip=True)

        if title:
            md = (f"# {title}\n\n" + md) if md else f"# {title}\n\n"

    try:
        return FetchResult(title=title, html_markdown=md)
    except Exception as e:
        print(f"åˆ›å»ºFetchResultå¤±è´¥: {e}")
        return FetchResult(title=None, html_markdown="")
